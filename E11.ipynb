{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87629e81-1b05-42eb-b0ac-95a7dd0adb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences=[]\n",
    "telugu_sentences=[]\n",
    "\n",
    "with open('MT Eng Tel Dataset.txt','r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        parts=line.split('\\t')\n",
    "        if len(parts)>=2:\n",
    "            english_sentences.append(parts[0].strip())\n",
    "            telugu_sentences.append(parts[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3a776c-3fcf-4870-beb9-d4864bec60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "source_texts=english_sentences\n",
    "target_texts=telugu_sentences\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(source_texts,target_texts,test_size=0.2,random_state=40)\n",
    "\n",
    "source_vocab=set(word_tokenize(\" \".join(source_texts)))\n",
    "target_vocab=set(word_tokenize(\" \".join(target_texts)))\n",
    "\n",
    "source_vocab_size = len(source_vocab) + 1\n",
    "target_vocab_size = len(target_vocab) + 1\n",
    "\n",
    "source_word_to_int = {word: idx + 1 for idx, word in enumerate(source_vocab)}\n",
    "target_word_to_int = {word: idx + 1 for idx, word in enumerate(target_vocab)}\n",
    "\n",
    "source_int_to_word={idx+1:word for idx,word in enumerate(source_vocab)}\n",
    "target_int_to_word={idx+1:word for idx,word in enumerate(target_vocab)}\n",
    "\n",
    "source_seq_train=[[source_word_to_int[word] for word in word_tokenize(sent)] for sent in X_train]\n",
    "target_seq_train=[[target_word_to_int[word] for word in word_tokenize(sent)] for sent in y_train]\n",
    "\n",
    "source_seq_test=[[source_word_to_int.get(word,0) for word in word_tokenize(sent)] for sent in X_test]\n",
    "target_seq_test=[[target_word_to_int.get(word,0) for word in word_tokenize(sent)] for sent in y_test]\n",
    "\n",
    "max_len=max(len(seq) for seq in source_seq_train+source_seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93e3bd6-fb02-4235-b505-c4bb5cfb4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "source_seq_train=pad_sequences(source_seq_train,maxlen=max_len)\n",
    "target_seq_train=pad_sequences(target_seq_train,maxlen=max_len)\n",
    "source_seq_test=pad_sequences(source_seq_test,maxlen=max_len)\n",
    "target_seq_test=pad_sequences(target_seq_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48367d7b-6353-4b78-b3a3-23199ed0d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense\n",
    "model=Sequential([\n",
    "    Embedding(source_vocab_size,64,input_length =max_len),\n",
    "    Dense(target_vocab_size),\n",
    "    SimpleRNN(128,return_sequences=True)\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76bebbb-1070-4d29-86b5-35a1e3292e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq_train=np.array(target_seq_train).reshape(-1,max_len)\n",
    "target_seq_test=np.array(target_seq_test).reshape(-1,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa1581d-6353-45ee-82ea-dbbb47ba4652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Tanuu\\AppData\\Local\\Temp\\ipykernel_19192\\273797817.py\", line 1, in <module>\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 446 which is outside the valid range of [0, 128).  Label values: 0 0 0 0 0 0 0 0 0 0 0 46 43 90 348 0 0 0 0 0 0 0 0 0 0 195 299 266 121 270 0 0 0 0 0 0 0 0 0 0 0 333 378 59 371 0 0 0 0 0 0 0 0 0 0 22 176 342 71 176 0 0 0 0 0 0 0 0 0 0 0 0 338 23 286 0 0 0 0 0 0 0 0 0 0 446 285 324 327 313 0 0 0 0 0 0 0 0 0 0 0 127 429 303 186 0 0 0 0 0 0 0 0 0 0 141 216 440 292 289 0 0 0 0 0 0 0 0 0 0 253 197 29 251 383 0 0 0 0 0 0 0 0 0 141 151 36 265 200 318 0 0 0 0 0 0 0 0 0 321 322 145 121 18 173 0 0 0 0 0 0 0 0 241 242 163 82 435 164 307 0 0 0 0 0 0 0 0 0 0 441 217 172 325 272 0 0 0 0 0 0 0 0 0 0 77 389 208 9 348 0 0 0 0 0 0 0 0 238 234 437 342 393 55 156 0 0 0 0 0 0 0 0 0 0 0 0 253 301 348 0 0 0 0 0 0 0 0 0 0 121 335 48 267 360 0 0 0 0 0 0 0 0 0 0 89 402 135 106 381 0 0 0 0 0 0 0 0 0 0 0 0 141 151 92 0 0 0 0 0 0 0 0 0 0 0 134 80 396 397 0 0 0 0 0 0 0 0 0 341 264 402 135 108 444 0 0 0 0 0 0 0 0 0 0 0 241 293 129 348 0 0 0 0 0 0 0 0 0 421 122 108 64 342 233 0 0 0 0 0 0 0 0 0 0 0 0 355 196 401 0 0 0 0 0 0 0 0 0 0 0 0 372 246 348 0 0 0 0 0 0 0 0 0 0 141 47 167 99 348 0 0 0 0 0 0 0 0 0 0 330 243 433 281 156 0 0 0 0 0 0 0 0 0 0 0 338 171 28 398 0 0 0 0 0 0 0 0 0 195 264 180 333 406 281 0 0 0 0 0 0 0 0 0 0 0 0 0 332 150 0 0 0 0 0 0 0 0 0 0 0 441 34 174 348 0 0 0 0 0 0 0 0 211 334 21 402 135 108 407\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_2330]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(source_seq_train, target_seq_train,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Tanuu\\AppData\\Local\\Temp\\ipykernel_19192\\273797817.py\", line 1, in <module>\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\Tanuu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 446 which is outside the valid range of [0, 128).  Label values: 0 0 0 0 0 0 0 0 0 0 0 46 43 90 348 0 0 0 0 0 0 0 0 0 0 195 299 266 121 270 0 0 0 0 0 0 0 0 0 0 0 333 378 59 371 0 0 0 0 0 0 0 0 0 0 22 176 342 71 176 0 0 0 0 0 0 0 0 0 0 0 0 338 23 286 0 0 0 0 0 0 0 0 0 0 446 285 324 327 313 0 0 0 0 0 0 0 0 0 0 0 127 429 303 186 0 0 0 0 0 0 0 0 0 0 141 216 440 292 289 0 0 0 0 0 0 0 0 0 0 253 197 29 251 383 0 0 0 0 0 0 0 0 0 141 151 36 265 200 318 0 0 0 0 0 0 0 0 0 321 322 145 121 18 173 0 0 0 0 0 0 0 0 241 242 163 82 435 164 307 0 0 0 0 0 0 0 0 0 0 441 217 172 325 272 0 0 0 0 0 0 0 0 0 0 77 389 208 9 348 0 0 0 0 0 0 0 0 238 234 437 342 393 55 156 0 0 0 0 0 0 0 0 0 0 0 0 253 301 348 0 0 0 0 0 0 0 0 0 0 121 335 48 267 360 0 0 0 0 0 0 0 0 0 0 89 402 135 106 381 0 0 0 0 0 0 0 0 0 0 0 0 141 151 92 0 0 0 0 0 0 0 0 0 0 0 134 80 396 397 0 0 0 0 0 0 0 0 0 341 264 402 135 108 444 0 0 0 0 0 0 0 0 0 0 0 241 293 129 348 0 0 0 0 0 0 0 0 0 421 122 108 64 342 233 0 0 0 0 0 0 0 0 0 0 0 0 355 196 401 0 0 0 0 0 0 0 0 0 0 0 0 372 246 348 0 0 0 0 0 0 0 0 0 0 141 47 167 99 348 0 0 0 0 0 0 0 0 0 0 330 243 433 281 156 0 0 0 0 0 0 0 0 0 0 0 338 171 28 398 0 0 0 0 0 0 0 0 0 195 264 180 333 406 281 0 0 0 0 0 0 0 0 0 0 0 0 0 332 150 0 0 0 0 0 0 0 0 0 0 0 441 34 174 348 0 0 0 0 0 0 0 0 211 334 21 402 135 108 407\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_2330]"
     ]
    }
   ],
   "source": [
    "model.fit(source_seq_train, target_seq_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78dede6a-2a87-4882-8687-78db755e8e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tanuu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.0312 - loss: 10.3379\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.1146 - loss: 7.2629\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.2292 - loss: 6.7611\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4167 - loss: 6.5001\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4271 - loss: 6.2831\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4583 - loss: 6.0834\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 4.3001\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5000 - loss: 3.8102\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6667 - loss: 3.6028\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6562 - loss: 3.4403\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6562 - loss: 3.2980\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6562 - loss: 3.1662\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6979 - loss: 3.0413\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7188 - loss: 2.8036\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7500 - loss: 2.3135\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7500 - loss: 2.0119\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7604 - loss: 1.9236\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7500 - loss: 1.8916\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7604 - loss: 1.5889\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7604 - loss: 1.4776\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7812 - loss: 1.3476\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7604 - loss: 1.2706\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7708 - loss: 1.2052\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7708 - loss: 1.1760\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7708 - loss: 1.0756\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7604 - loss: 1.0459\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7604 - loss: 0.9773\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7500 - loss: 1.0055\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7396 - loss: 1.1929\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7500 - loss: 1.1098\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7500 - loss: 1.1025\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7396 - loss: 1.0989\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7188 - loss: 1.1774\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7188 - loss: 1.2685\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7292 - loss: 1.3753\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7396 - loss: 1.1846\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7396 - loss: 1.3421\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7292 - loss: 1.1835\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7292 - loss: 1.2233\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7083 - loss: 1.2237\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6979 - loss: 1.3828\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6875 - loss: 1.3833\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6771 - loss: 1.4237\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6771 - loss: 1.5036\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6771 - loss: 1.5041\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6562 - loss: 1.5440\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6562 - loss: 1.5441\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6562 - loss: 1.5441\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6458 - loss: 1.5439\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6458 - loss: 1.5436\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6458 - loss: 1.5436\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6250 - loss: 1.5426\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6146 - loss: 1.5420\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6146 - loss: 1.5414\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.6042 - loss: 1.6083\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6146 - loss: 1.5446\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6042 - loss: 1.6213\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6042 - loss: 1.5488\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6042 - loss: 1.5498\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5938 - loss: 1.5508\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5938 - loss: 1.5511\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5938 - loss: 1.5496\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5938 - loss: 1.6250\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5938 - loss: 1.5430\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6042 - loss: 1.5404\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6146 - loss: 1.5382\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6250 - loss: 1.5363\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6250 - loss: 1.5355\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6250 - loss: 1.5349\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6250 - loss: 1.5344\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6354 - loss: 1.5341\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6354 - loss: 1.5338\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6354 - loss: 1.5734\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6354 - loss: 1.5734\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6354 - loss: 1.5735\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6354 - loss: 1.5736\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6354 - loss: 1.5739\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6354 - loss: 1.5736\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6354 - loss: 1.5731\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6354 - loss: 1.5728\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6354 - loss: 1.5725\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6354 - loss: 1.5722\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6354 - loss: 1.5720\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6354 - loss: 1.5718\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6354 - loss: 1.5716\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6354 - loss: 1.5715\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6354 - loss: 1.5715\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6354 - loss: 1.5715\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6354 - loss: 1.5715\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6354 - loss: 1.5714\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6354 - loss: 1.5714\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6354 - loss: 1.5713\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6354 - loss: 1.5713\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6354 - loss: 1.5712\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6354 - loss: 1.5711\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6354 - loss: 1.5710\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6354 - loss: 1.5709\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6354 - loss: 1.5708\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6354 - loss: 1.5707\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6354 - loss: 1.5706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2acd7ef3140>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "source_texts = english_sentences[:20]\n",
    "target_texts =telugu_sentences[:20]\n",
    "\n",
    "# Split the data\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(source_texts, target_texts, test_size=0.2, random_state=40)\n",
    "\n",
    "# Create vocabulary from the entire dataset\n",
    "source_vocab = set(word_tokenize(\" \".join(source_texts)))\n",
    "target_vocab = set(word_tokenize(\" \".join(target_texts)))\n",
    "\n",
    "source_vocab_size = len(source_vocab) + 1\n",
    "target_vocab_size = len(target_vocab) + 1\n",
    "\n",
    "# Create mappings from words to integers and vice versa\n",
    "source_word_to_int = {word: idx + 1 for idx, word in enumerate(source_vocab)}\n",
    "target_word_to_int = {word: idx + 1 for idx, word in enumerate(target_vocab)}\n",
    "\n",
    "source_int_to_word = {idx + 1: word for idx, word in enumerate(source_vocab)}\n",
    "target_int_to_word = {idx + 1: word for idx, word in enumerate(target_vocab)}\n",
    "\n",
    "# Encode the training and test sequences\n",
    "source_sequences_train = [[source_word_to_int[word] for word in word_tokenize(text)] for text in Xtrain]\n",
    "target_sequences_train = [[target_word_to_int[word] for word in word_tokenize(text)] for text in Ytrain]\n",
    "\n",
    "source_sequences_test = [[source_word_to_int.get(word, 0) for word in word_tokenize(text)] for text in Xtest]\n",
    "target_sequences_test = [[target_word_to_int.get(word, 0) for word in word_tokenize(text)] for text in Ytest]\n",
    "\n",
    "# Find maximum sequence length\n",
    "max_sequence_length = max(len(seq) for seq in source_sequences_train + source_sequences_test)\n",
    "\n",
    "# Pad sequences\n",
    "source_sequences_train = tf.keras.preprocessing.sequence.pad_sequences(source_sequences_train, maxlen=max_sequence_length)\n",
    "target_sequences_train = tf.keras.preprocessing.sequence.pad_sequences(target_sequences_train, maxlen=max_sequence_length)\n",
    "source_sequences_test = tf.keras.preprocessing.sequence.pad_sequences(source_sequences_test, maxlen=max_sequence_length)\n",
    "target_sequences_test = tf.keras.preprocessing.sequence.pad_sequences(target_sequences_test, maxlen=max_sequence_length)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(source_vocab_size,64,input_length=max_sequence_length),\n",
    "    tf.keras.layers.SimpleRNN(128,return_sequences=True),\n",
    "    tf.keras.layers.Dense(target_vocab_size)\n",
    "])\n",
    "\n",
    "# Compile the model with sparse categorical cross-entropy\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape target sequences to match expected input for sparse categorical loss\n",
    "target_sequences_train = np.array(target_sequences_train).reshape(-1, max_sequence_length)\n",
    "target_sequences_test = np.array(target_sequences_test).reshape(-1, max_sequence_length)\n",
    "\n",
    "# Train the model with validation data\n",
    "model.fit(source_sequences_train, target_sequences_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1ab0571-51e3-4426-ab61-4c4dbc63bec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "[[ 0.24508259 -0.05504403 -0.11816098 -0.10837324 -0.07255821 -0.11998067\n",
      "  -0.10737084 -0.08569762 -0.0803718  -0.11490519 -0.02560244 -0.03243835\n",
      "  -0.043842   -0.1041599  -0.13020249 -0.08101579 -0.05162875 -0.00438696\n",
      "  -0.08297829 -0.18998423 -0.07529364 -0.06473194 -0.07605205 -0.07820453\n",
      "  -0.08212771 -0.03844244 -0.07698224 -0.14655462 -0.07531939 -0.04842335\n",
      "  -0.05894873 -0.09364062 -0.02390634 -0.09341303 -0.05079287 -0.08263737\n",
      "  -0.10996032 -0.08191808 -0.04155309 -0.05800946 -0.06546939 -0.05662285\n",
      "  -0.06840488 -0.07129075 -0.10970235]\n",
      " [ 0.40914214 -0.02569636 -0.23750997 -0.14189595 -0.0908417  -0.18009129\n",
      "  -0.17645943 -0.09784844 -0.25787908 -0.19914463 -0.06330021 -0.13357814\n",
      "  -0.14577241 -0.23374496 -0.2170155  -0.15386048 -0.10210229 -0.05761316\n",
      "  -0.2665504  -0.3610595  -0.16296345 -0.08378059 -0.14588526 -0.1373244\n",
      "  -0.18671787 -0.08754131 -0.16939737 -0.2985636  -0.1044628  -0.15426172\n",
      "  -0.08986133 -0.1800989  -0.10586187 -0.16054125 -0.08451372 -0.16396561\n",
      "  -0.24947941 -0.18004282 -0.11863484 -0.11243691 -0.12061598 -0.16025525\n",
      "  -0.04652815 -0.16870692 -0.21702604]\n",
      " [ 0.31192958 -0.01812399 -0.37912247 -0.231731   -0.07375148 -0.18117422\n",
      "  -0.24733758 -0.17177115 -0.5110722  -0.31425387 -0.17426741 -0.35307917\n",
      "  -0.36731505 -0.34272975 -0.39407286 -0.26513112 -0.28122693 -0.18885678\n",
      "  -0.45225364 -0.51081306 -0.28541973 -0.24128805 -0.1514247  -0.15575872\n",
      "  -0.32822546 -0.14533274 -0.2571804  -0.7024608  -0.15286523 -0.26036772\n",
      "  -0.19550045 -0.22316724 -0.1949558  -0.31263348 -0.17448954 -0.2756939\n",
      "  -0.36573708 -0.29745132 -0.13998014 -0.20272978 -0.19261064 -0.21266633\n",
      "  -0.10467202 -0.30045134 -0.36502832]\n",
      " [-0.05133537 -0.04476318 -0.43045285 -0.35859904 -0.06663047 -0.2721324\n",
      "  -0.29921213 -0.29190728 -0.7856374  -0.42846686 -0.3015902  -0.7187486\n",
      "  -0.42233086 -0.4399321  -0.563495   -0.3869954  -0.49843603 -0.44489112\n",
      "  -0.6418331  -0.5659259  -0.39066833 -0.55943346 -0.16789317 -0.24907029\n",
      "  -0.50763863 -0.22300132 -0.4250146  -1.222847   -0.26529577 -0.32670355\n",
      "  -0.31246752 -0.26411152 -0.30333596 -0.5460673  -0.33059147 -0.46520513\n",
      "  -0.41175222 -0.46646506 -0.24936157 -0.28162086 -0.44110277 -0.2741684\n",
      "  -0.25678435 -0.35684818 -0.42557204]\n",
      " [-0.41461432 -0.18956855 -0.42440903 -0.53525054 -0.21203169 -0.3993439\n",
      "  -0.30310953 -0.37567604 -0.83493924 -0.5317617  -0.38712764 -1.0522584\n",
      "  -0.49247676 -0.49844876 -0.68549794 -0.48599848 -0.64817315 -0.62148064\n",
      "  -0.6539141  -0.5473682  -0.46692908 -0.91219985 -0.24167636 -0.4309049\n",
      "  -0.46470505 -0.44023845 -0.55319875 -1.3975058  -0.38822615 -0.37232333\n",
      "  -0.5067173  -0.34076253 -0.32630965 -0.63486344 -0.4382987  -0.730784\n",
      "  -0.56084096 -0.5724809  -0.27296466 -0.37424564 -0.6366064  -0.38192138\n",
      "  -0.442914   -0.39894974 -0.56130064]\n",
      " [-0.35640866 -0.21645498 -0.47783136 -0.71560454 -0.29671094 -0.5990501\n",
      "  -0.29045904 -0.5236337  -0.765169   -0.7486065  -0.51550275 -1.0043558\n",
      "  -0.46364516 -0.4412344  -0.9139747  -0.5525739  -0.76205873 -0.7731311\n",
      "  -0.783629   -0.7606821  -0.50540036 -1.0997806  -0.35622072 -0.66614413\n",
      "  -0.6912647  -0.52609885 -0.72479385 -1.4576507  -0.5608322  -0.4096032\n",
      "  -0.66613615 -0.38759503 -0.28190535 -0.7388573  -0.4890411  -0.7956243\n",
      "  -0.70924443 -0.7376728  -0.34992757 -0.5145891  -0.70223427 -0.3824977\n",
      "  -0.58752495 -0.5041302  -0.6551112 ]]\n",
      "Translated Sequence: నాకు నాకు నాకు\n"
     ]
    }
   ],
   "source": [
    "# Translation process\n",
    "input_sequence = \"I ran home.\"\n",
    "input_sequence = [source_word_to_int.get(word, 0) for word in input_sequence.split()]\n",
    "input_sequence = tf.keras.preprocessing.sequence.pad_sequences([input_sequence], maxlen=max_sequence_length)\n",
    "\n",
    "# Predict the output sequence\n",
    "output_sequence = model.predict(input_sequence)[0]\n",
    "print(output_sequence)\n",
    "output_sequence = [target_int_to_word[np.argmax(word)] for word in output_sequence if np.argmax(word) != 0]\n",
    "\n",
    "print(\"Translated Sequence:\", ' '.join(output_sequence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
